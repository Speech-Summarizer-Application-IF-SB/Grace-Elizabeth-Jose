# -*- coding: utf-8 -*-
"""SpeechSummarizer_Application.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VbdIEZP83VKNja8c9pOUVELQLWMse2f5
"""

!nvidia-smi

# Step 0: Install necessary packages
!pip install transformers datasets torch soundfile librosa

# Step 1: Import libraries
from transformers import pipeline
from google.colab import files

# Step 2: Upload your audio file
print("Upload a WAV audio file (short meeting clip recommended)")
uploaded = files.upload()  # Select audio.wav from your computer
audio_file = list(uploaded.keys())[0]

# Step 3: Initialize Whisper STT model
print("Loading Whisper model...")
stt = pipeline("automatic-speech-recognition", model="openai/whisper-small")

# Step 4: Transcribe the audio
print("Transcribing audio...")
transcription_result = stt(audio_file)
transcription_text = transcription_result["text"]
print("\n--- Transcription ---")
print(transcription_text)

# Step 5: Initialize BART summarization model
print("\nLoading BART summarization model...")
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# Step 6: Generate summary
print("Generating summary...")
summary_result = summarizer(transcription_text, max_length=100, min_length=30, do_sample=False)
summary_text = summary_result[0]["summary_text"]

print("\n--- Summary ---")
print(summary_text)

